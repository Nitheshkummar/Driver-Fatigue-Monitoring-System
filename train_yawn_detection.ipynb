{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8da82",
   "metadata": {},
   "source": [
    "# Yawn Detection Model Training for ESP32\n",
    "## TinyML Model for Driver Drowsiness Detection System\n",
    "\n",
    "**Target Specifications:**\n",
    "- Model Size: <25KB (optimized for ESP32)\n",
    "- Accuracy: >90%\n",
    "- Input: 32x32 grayscale mouth region images\n",
    "- Output: Binary classification (0=Normal, 1=Yawning)\n",
    "\n",
    "**Reference System:**\n",
    "Based on `drowsiness_detect.py` which uses:\n",
    "- MAR (Mouth Aspect Ratio) threshold = 0.6 for yawning\n",
    "- YAWN_FRAMES_THRESHOLD = 15 consecutive frames\n",
    "\n",
    "**Purpose:**\n",
    "Train a lightweight CNN to detect yawning for integration with ESP32-based driver fatigue monitoring system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b348d8",
   "metadata": {},
   "source": [
    "## STAGE 1: Import Libraries and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375cf2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "============================================================================\n",
    "YAWN DETECTION MODEL TRAINING FOR ESP32\n",
    "============================================================================\n",
    "Input: 32x32 grayscale mouth region images\n",
    "Output: Binary (0=Normal, 1=Yawning)\n",
    "============================================================================\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from scipy.spatial import distance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "print(\"OpenCV version:\", cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec77a94",
   "metadata": {},
   "source": [
    "## STAGE 1: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f11859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Configuration\n",
    "IMG_SIZE = 32  # 32x32 pixels for mouth region\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 40\n",
    "MODEL_NAME = 'yawn_detection_model'\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Reference from drowsiness_detect.py\n",
    "MOUTH_ASPECT_RATIO_THRESHOLD = 0.6  # MAR threshold for yawning\n",
    "YAWN_FRAMES_THRESHOLD = 15  # Consecutive frames\n",
    "\n",
    "# Dataset paths\n",
    "DATASET_DIR = '../datasets/processed'\n",
    "RAW_DATASET_DIR = '../datasets/raw'\n",
    "\n",
    "# Training parameters\n",
    "VALIDATION_SPLIT = 0.2\n",
    "TEST_SPLIT = 0.2\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"YAWN DETECTION - TinyML Training Configuration\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Image Size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Model Name: {MODEL_NAME}\")\n",
    "print(f\"MAR Threshold (Reference): {MOUTH_ASPECT_RATIO_THRESHOLD}\")\n",
    "print(f\"Target: <25KB model, >90% accuracy\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf345715",
   "metadata": {},
   "source": [
    "## STAGE 2: Helper Functions - MAR Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fedb1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mouth_aspect_ratio(mouth_points):\n",
    "    \"\"\"\n",
    "    Calculate Mouth Aspect Ratio (MAR) from mouth landmark points.\n",
    "    Based on the formula from drowsiness_detect.py:\n",
    "    MAR = (A + B) / (2 * C)\n",
    "    \n",
    "    Args:\n",
    "        mouth_points: Array of mouth landmark coordinates\n",
    "    \n",
    "    Returns:\n",
    "        float: MAR value (>0.6 typically indicates yawning)\n",
    "    \"\"\"\n",
    "    # Vertical distances\n",
    "    A = distance.euclidean(mouth_points[2], mouth_points[10])  # 51, 59\n",
    "    B = distance.euclidean(mouth_points[4], mouth_points[8])   # 53, 57\n",
    "    \n",
    "    # Horizontal distance\n",
    "    C = distance.euclidean(mouth_points[0], mouth_points[6])   # 49, 55\n",
    "    \n",
    "    # Calculate MAR\n",
    "    mar = (A + B) / (2.0 * C)\n",
    "    \n",
    "    return mar\n",
    "\n",
    "# Test with sample data\n",
    "sample_normal = np.array([[0,0], [5,2], [10,3], [20,0], [15,-2], [10,-3], [5,-2], [3,0], [8,1], [12,0], [10,-1]])\n",
    "sample_yawn = np.array([[0,0], [5,8], [10,12], [20,0], [15,-8], [10,-12], [5,-8], [3,0], [8,5], [12,0], [10,-5]])\n",
    "\n",
    "print(\"Sample MAR calculations:\")\n",
    "print(f\"Normal mouth MAR: {mouth_aspect_ratio(sample_normal):.3f}\")\n",
    "print(f\"Yawning mouth MAR: {mouth_aspect_ratio(sample_yawn):.3f}\")\n",
    "print(f\"Threshold: {MOUTH_ASPECT_RATIO_THRESHOLD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe51603",
   "metadata": {},
   "source": [
    "## STAGE 3: Check Dataset Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca29176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset_availability():\n",
    "    \"\"\"Check if datasets exist and display statistics\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Checking Dataset Availability\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    datasets_found = False\n",
    "    \n",
    "    if os.path.exists(DATASET_DIR):\n",
    "        print(f\"\\n✓ Processed dataset directory found: {DATASET_DIR}\")\n",
    "        \n",
    "        # Check normal mouth\n",
    "        normal_dir = os.path.join(DATASET_DIR, 'mouth_normal')\n",
    "        if os.path.exists(normal_dir):\n",
    "            normal_count = len([f for f in os.listdir(normal_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "            print(f\"  ✓ Normal mouth images: {normal_count} files\")\n",
    "            if normal_count > 0:\n",
    "                datasets_found = True\n",
    "        else:\n",
    "            print(f\"  ✗ Normal mouth directory not found\")\n",
    "        \n",
    "        # Check yawning mouth\n",
    "        yawn_dir = os.path.join(DATASET_DIR, 'mouth_yawn')\n",
    "        if os.path.exists(yawn_dir):\n",
    "            yawn_count = len([f for f in os.listdir(yawn_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "            print(f\"  ✓ Yawning mouth images: {yawn_count} files\")\n",
    "            if yawn_count > 0:\n",
    "                datasets_found = True\n",
    "        else:\n",
    "            print(f\"  ✗ Yawning mouth directory not found\")\n",
    "    else:\n",
    "        print(f\"\\n✗ Processed dataset directory not found: {DATASET_DIR}\")\n",
    "    \n",
    "    if not datasets_found:\n",
    "        print(\"\\n  WARNING: No processed datasets found!\")\n",
    "        print(\"\\n  Recommended: YawDD Dataset from http://www.site.uottawa.ca/~shervin/yawning/\")\n",
    "        print(\"   OR use generate_sample_dataset() to create synthetic data for testing\")\n",
    "    else:\n",
    "        print(\"\\n  Dataset is available and ready for training!\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    return datasets_found\n",
    "\n",
    "# Check datasets\n",
    "dataset_available = check_dataset_availability()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3e704c",
   "metadata": {},
   "source": [
    "## STAGE 4: Generate Sample Dataset (Optional)\n",
    "Run this cell only if you don't have real datasets. This creates synthetic mouth images for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a958e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_dataset(num_samples=500):\n",
    "    \"\"\"Generate synthetic mouth images for testing\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Generating Sample Dataset\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    os.makedirs(os.path.join(DATASET_DIR, 'mouth_normal'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(DATASET_DIR, 'mouth_yawn'), exist_ok=True)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Normal mouth (horizontal ellipse)\n",
    "        img_normal = np.ones((IMG_SIZE, IMG_SIZE), dtype=np.uint8) * 200\n",
    "        cv2.ellipse(img_normal, (IMG_SIZE//2, IMG_SIZE//2), (10, 4), 0, 0, 360, 0, -1)\n",
    "        noise = np.random.randint(-20, 20, (IMG_SIZE, IMG_SIZE), dtype=np.int16)\n",
    "        img_normal = np.clip(img_normal.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "        cv2.imwrite(os.path.join(DATASET_DIR, 'mouth_normal', f'normal_{i:04d}.png'), img_normal)\n",
    "        \n",
    "        # Yawning mouth (vertical ellipse)\n",
    "        img_yawn = np.ones((IMG_SIZE, IMG_SIZE), dtype=np.uint8) * 200\n",
    "        cv2.ellipse(img_yawn, (IMG_SIZE//2, IMG_SIZE//2), (8, 12), 0, 0, 360, 0, -1)\n",
    "        noise = np.random.randint(-20, 20, (IMG_SIZE, IMG_SIZE), dtype=np.int16)\n",
    "        img_yawn = np.clip(img_yawn.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "        cv2.imwrite(os.path.join(DATASET_DIR, 'mouth_yawn', f'yawn_{i:04d}.png'), img_yawn)\n",
    "    \n",
    "    print(f\"\\n✓ Generated {num_samples} normal mouth images\")\n",
    "    print(f\"✓ Generated {num_samples} yawning mouth images\")\n",
    "    print(f\"✓ Total: {num_samples * 2} synthetic images\")\n",
    "    print(\"\\n  Note: This is synthetic data for testing. Use real datasets for production.\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# Uncomment the line below to generate synthetic data if no real dataset is available\n",
    "# if not dataset_available:\n",
    "#     generate_sample_dataset(500)\n",
    "#     dataset_available = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54164aac",
   "metadata": {},
   "source": [
    "## STAGE 5: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1a2cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_dir=DATASET_DIR):\n",
    "    \"\"\"Load preprocessed mouth images\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Loading Dataset\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    # Load normal mouth (label = 0)\n",
    "    normal_dir = os.path.join(data_dir, 'mouth_normal')\n",
    "    if os.path.exists(normal_dir):\n",
    "        normal_files = [f for f in os.listdir(normal_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        print(f\"\\nLoading {len(normal_files)} normal mouth images...\")\n",
    "        for img_file in normal_files:\n",
    "            img = cv2.imread(os.path.join(normal_dir, img_file), cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                X.append(img)\n",
    "                y.append(0)\n",
    "    \n",
    "    # Load yawning mouth (label = 1)\n",
    "    yawn_dir = os.path.join(data_dir, 'mouth_yawn')\n",
    "    if os.path.exists(yawn_dir):\n",
    "        yawn_files = [f for f in os.listdir(yawn_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        print(f\"Loading {len(yawn_files)} yawning mouth images...\")\n",
    "        for img_file in yawn_files:\n",
    "            img = cv2.imread(os.path.join(yawn_dir, img_file), cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                X.append(img)\n",
    "                y.append(1)\n",
    "    \n",
    "    # Convert to numpy arrays and normalize\n",
    "    X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1) / 255.0\n",
    "    y = np.array(y)\n",
    "    \n",
    "    print(f\"\\n✓ Loaded {len(X)} images total\")\n",
    "    print(f\"  - Normal (0): {np.sum(y == 0)} images\")\n",
    "    print(f\"  - Yawning (1): {np.sum(y == 1)} images\")\n",
    "    print(f\"\\nDataset shape: {X.shape}\")\n",
    "    print(f\"Value range: [{X.min():.3f}, {X.max():.3f}]\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    X, y = load_dataset()\n",
    "    if len(X) == 0:\n",
    "        print(\"\\n  No data found! Generate sample data or provide real dataset.\")\n",
    "    else:\n",
    "        print(\"\\n Dataset loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n Error loading dataset: {e}\")\n",
    "    X, y = np.array([]), np.array([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e50eb51",
   "metadata": {},
   "source": [
    "## STAGE 6: Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae997f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X) > 0:\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 4))\n",
    "    fig.suptitle('Sample Mouth Images', fontsize=16)\n",
    "    \n",
    "    # Get sample indices\n",
    "    normal_indices = np.where(y == 0)[0][:5]\n",
    "    yawn_indices = np.where(y == 1)[0][:5]\n",
    "    \n",
    "    # Plot normal samples\n",
    "    for i, idx in enumerate(normal_indices):\n",
    "        axes[0, i].imshow(X[idx].reshape(IMG_SIZE, IMG_SIZE), cmap='gray')\n",
    "        axes[0, i].set_title(f'Normal #{i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "    \n",
    "    # Plot yawning samples\n",
    "    for i, idx in enumerate(yawn_indices):\n",
    "        axes[1, i].imshow(X[idx].reshape(IMG_SIZE, IMG_SIZE), cmap='gray')\n",
    "        axes[1, i].set_title(f'Yawning #{i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Class distribution\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    ax.bar(['Normal', 'Yawning'], counts, color=['green', 'orange'])\n",
    "    ax.set_ylabel('Number of Images')\n",
    "    ax.set_title('Class Distribution')\n",
    "    for i, count in enumerate(counts):\n",
    "        ax.text(i, count, str(count), ha='center', va='bottom')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070569b6",
   "metadata": {},
   "source": [
    "## STAGE 7: Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb99e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X) > 0:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SPLIT, random_state=RANDOM_SEED, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(\"\\n Dataset Split:\")\n",
    "    print(f\"  Training set: {len(X_train)} images\")\n",
    "    print(f\"    - Normal: {np.sum(y_train == 0)}\")\n",
    "    print(f\"    - Yawning: {np.sum(y_train == 1)}\")\n",
    "    print(f\"\\n  Test set: {len(X_test)} images\")\n",
    "    print(f\"    - Normal: {np.sum(y_test == 0)}\")\n",
    "    print(f\"    - Yawning: {np.sum(y_test == 1)}\")\n",
    "else:\n",
    "    print(\"  Cannot split dataset - no data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874f9b9e",
   "metadata": {},
   "source": [
    "## STAGE 8: Create Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736af588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"Create lightweight CNN for yawn detection\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(IMG_SIZE, IMG_SIZE, 1), name='input'),\n",
    "        \n",
    "        # Conv Block 1\n",
    "        layers.Conv2D(16, (3, 3), activation='relu', padding='same', name='conv1'),\n",
    "        layers.MaxPooling2D((2, 2), name='pool1'),\n",
    "        layers.Dropout(0.2, name='dropout1'),\n",
    "        \n",
    "        # Conv Block 2\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv2'),\n",
    "        layers.MaxPooling2D((2, 2), name='pool2'),\n",
    "        layers.Dropout(0.2, name='dropout2'),\n",
    "        \n",
    "        # Dense Layers\n",
    "        layers.Flatten(name='flatten'),\n",
    "        layers.Dense(16, activation='relu', name='dense1'),\n",
    "        layers.Dropout(0.3, name='dropout3'),\n",
    "        layers.Dense(1, activation='sigmoid', name='output')\n",
    "    ], name='yawn_detector')\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and display model\n",
    "model = create_model()\n",
    "model.summary()\n",
    "\n",
    "# Calculate model size\n",
    "total_params = model.count_params()\n",
    "print(f\"\\n Model Size:\")\n",
    "print(f\"   Parameters: {total_params:,}\")\n",
    "print(f\"   FP32: {total_params * 4 / 1024:.2f} KB\")\n",
    "print(f\"   INT8: {total_params / 1024:.2f} KB\")\n",
    "print(f\"   Target: <25 KB {'✓' if total_params / 1024 < 25 else '✗'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a43a2fa",
   "metadata": {},
   "source": [
    "## STAGE 9: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea003935",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X) > 0:\n",
    "    print(\"\\n Starting training...\\n\")\n",
    "    \n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=0.00001,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            f'{MODEL_NAME}_best.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_split=VALIDATION_SPLIT,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"\\n Training completed!\")\n",
    "else:\n",
    "    print(\"  Cannot train - no data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e082ef8f",
   "metadata": {},
   "source": [
    "## STAGE 10: Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9564eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "    axes[0].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Accuracy')\n",
    "    axes[0].set_title('Model Accuracy')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss\n",
    "    axes[1].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "    axes[1].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].set_title('Model Loss')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e004ac",
   "metadata": {},
   "source": [
    "## STAGE 11: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fe8c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X) > 0:\n",
    "    print(\"\\n Evaluating model on test set...\\n\")\n",
    "    \n",
    "    test_loss, test_acc, test_precision, test_recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "    f1_score = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
    "    \n",
    "    print(f\"Test Accuracy:  {test_acc * 100:.2f}%\")\n",
    "    print(f\"Test Loss:      {test_loss:.4f}\")\n",
    "    print(f\"Test Precision: {test_precision:.4f}\")\n",
    "    print(f\"Test Recall:    {test_recall:.4f}\")\n",
    "    print(f\"F1-Score:       {f1_score:.4f}\")\n",
    "    \n",
    "    if test_acc >= 0.90:\n",
    "        print(\"\\n Target accuracy (>90%) achieved!\")\n",
    "    else:\n",
    "        print(f\"\\n Target not met. Current: {test_acc*100:.2f}%, Target: >90%\")\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_prob = model.predict(X_test, verbose=0)\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.set_xticklabels(['Normal', 'Yawning'])\n",
    "    ax.set_yticklabels(['Normal', 'Yawning'])\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification Report\n",
    "    print(\"\\n Classification Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Normal', 'Yawning']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec50ca",
   "metadata": {},
   "source": [
    "## STAGE 12: Convert to TensorFlow Lite for ESP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f2db7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tflite(model, model_name):\n",
    "    \"\"\"Convert Keras model to TensorFlow Lite\"\"\"\n",
    "    print(\"\\n Converting to TensorFlow Lite...\\n\")\n",
    "    \n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    # Save TFLite\n",
    "    tflite_filename = f'{model_name}.tflite'\n",
    "    with open(tflite_filename, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    \n",
    "    print(f\"✓ Saved: {tflite_filename}\")\n",
    "    print(f\"✓ Model size: {len(tflite_model) / 1024:.2f} KB\")\n",
    "    \n",
    "    if len(tflite_model) / 1024 < 25:\n",
    "        print(\" Size target met (<25KB)!\")\n",
    "    \n",
    "    # Save as C header for ESP32\n",
    "    h_filename = f'{model_name}.h'\n",
    "    with open(h_filename, 'w') as f:\n",
    "        f.write(f\"// Auto-generated for ESP32\\n\")\n",
    "        f.write(f\"// Model: {model_name}\\n\")\n",
    "        f.write(f\"// Size: {len(tflite_model)} bytes\\n\\n\")\n",
    "        f.write(f\"#ifndef {model_name.upper()}_H\\n\")\n",
    "        f.write(f\"#define {model_name.upper()}_H\\n\\n\")\n",
    "        f.write(f\"const unsigned char {model_name}_tflite[] = {{\\n\")\n",
    "        \n",
    "        hex_array = [f\"0x{byte:02x}\" for byte in tflite_model]\n",
    "        for i in range(0, len(hex_array), 12):\n",
    "            f.write(\"  \" + \", \".join(hex_array[i:i+12]) + \",\\n\")\n",
    "        \n",
    "        f.write(\"};\\n\\n\")\n",
    "        f.write(f\"const unsigned int {model_name}_tflite_len = {len(tflite_model)};\\n\\n\")\n",
    "        f.write(f\"#endif\\n\")\n",
    "    \n",
    "    print(f\"✓ Saved: {h_filename}\")\n",
    "    print(\"\\n Conversion completed!\")\n",
    "    \n",
    "    return tflite_model\n",
    "\n",
    "# Convert model\n",
    "if len(X) > 0:\n",
    "    tflite_model = convert_to_tflite(model, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206d8f7f",
   "metadata": {},
   "source": [
    "## STAGE 13: Save Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b39356",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X) > 0:\n",
    "    keras_filename = f'{MODEL_NAME}.h5'\n",
    "    model.save(keras_filename)\n",
    "    print(f\"✓ Saved Keras model: {keras_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54d6c1b",
   "metadata": {},
   "source": [
    "## STAGE 14: Test Inference Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f4b5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X) > 0:\n",
    "    import time\n",
    "    \n",
    "    print(\"\\n  Testing inference speed...\\n\")\n",
    "    \n",
    "    test_image = X_test[0:1]\n",
    "    \n",
    "    # Warm up\n",
    "    for _ in range(10):\n",
    "        _ = model.predict(test_image, verbose=0)\n",
    "    \n",
    "    # Measure\n",
    "    num_iterations = 100\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_iterations):\n",
    "        _ = model.predict(test_image, verbose=0)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    avg_time = (end_time - start_time) / num_iterations * 1000\n",
    "    fps = 1000 / avg_time\n",
    "    \n",
    "    print(f\"Average inference time: {avg_time:.2f} ms\")\n",
    "    print(f\"Estimated FPS: {fps:.2f}\")\n",
    "    print(\"\\nNote: ESP32 will be slower (~50-100ms per inference)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
