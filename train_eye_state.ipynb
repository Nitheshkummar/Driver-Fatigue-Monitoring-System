{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73c8326",
   "metadata": {},
   "source": [
    "# Eye State Detection Model Training for ESP32\n",
    "\n",
    "This notebook trains a lightweight CNN model for detecting eye states (open/closed) to deploy on ESP32-CAM for driver drowsiness detection.\n",
    "\n",
    "**Target Specifications:**\n",
    "- Accuracy: >95%\n",
    "- Input: 24x24 grayscale eye region images\n",
    "- Output: Binary (0=Open, 1=Closed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e567efa6",
   "metadata": {},
   "source": [
    "## STAGE 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebd7ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "============================================================================\n",
    "EYE STATE DETECTION MODEL TRAINING FOR ESP32\n",
    "============================================================================\n",
    "\n",
    "Input: 24x24 grayscale eye region images\n",
    "Output: Binary (0=Open, 1=Closed)\n",
    "\n",
    "============================================================================\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from scipy.spatial import distance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "print(\"OpenCV version:\", cv2.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865aad3d",
   "metadata": {},
   "source": [
    "## STAGE 2: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c461870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Configuration\n",
    "IMG_SIZE = 24  # 24x24 pixels for eye region\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "MODEL_NAME = 'eye_state_model'\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Reference from drowsiness_detect.py\n",
    "EYE_ASPECT_RATIO_THRESHOLD = 0.25  # EAR threshold for closed eyes\n",
    "DROWSY_FRAMES_THRESHOLD = 50  # Consecutive frames before alarm\n",
    "\n",
    "# Dataset paths\n",
    "DATASET_DIR = '../datasets/processed'\n",
    "RAW_DATASET_DIR = '../datasets/raw'\n",
    "\n",
    "# Training parameters\n",
    "VALIDATION_SPLIT = 0.2\n",
    "TEST_SPLIT = 0.2\n",
    "RANDOM_SEED = 42\n",
    "USE_DATA_AUGMENTATION = True\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EYE STATE DETECTION - TinyML Training Configuration\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Image Size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Model Name: {MODEL_NAME}\")\n",
    "print(f\"EAR Threshold (Reference): {EYE_ASPECT_RATIO_THRESHOLD}\")\n",
    "print(f\"Data Augmentation: {USE_DATA_AUGMENTATION}\")\n",
    "print(f\"Target: <20KB model, >95% accuracy\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272a1c2a",
   "metadata": {},
   "source": [
    "## STAGE 3: Helper Functions - EAR Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb9c796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye_points):\n",
    "    \"\"\"\n",
    "    Calculate Eye Aspect Ratio (EAR) from eye landmark points.\n",
    "    Based on the formula from drowsiness_detect.py:\n",
    "    EAR = (A + B) / (2 * C)\n",
    "    \n",
    "    Args:\n",
    "        eye_points: Array of 6 eye landmark coordinates (x, y)\n",
    "    \n",
    "    Returns:\n",
    "        float: EAR value (<0.25 typically indicates closed eyes)\n",
    "    \"\"\"\n",
    "    # Vertical eye distances\n",
    "    A = distance.euclidean(eye_points[1], eye_points[5])\n",
    "    B = distance.euclidean(eye_points[2], eye_points[4])\n",
    "    \n",
    "    # Horizontal eye distance\n",
    "    C = distance.euclidean(eye_points[0], eye_points[3])\n",
    "    \n",
    "    # Calculate EAR\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    \n",
    "    return ear\n",
    "\n",
    "# Test with sample data\n",
    "sample_open = np.array([[0,5], [3,8], [6,8], [15,5], [6,2], [3,2]])\n",
    "sample_closed = np.array([[0,5], [3,5.5], [6,5.5], [15,5], [6,4.5], [3,4.5]])\n",
    "\n",
    "print(\"Sample EAR calculations:\")\n",
    "print(f\"Open eye EAR: {eye_aspect_ratio(sample_open):.3f}\")\n",
    "print(f\"Closed eye EAR: {eye_aspect_ratio(sample_closed):.3f}\")\n",
    "print(f\"Threshold: {EYE_ASPECT_RATIO_THRESHOLD}\")\n",
    "print(f\"Interpretation: EAR < {EYE_ASPECT_RATIO_THRESHOLD} = Closed eye\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b2752d",
   "metadata": {},
   "source": [
    "## STAGE 4: Check Dataset Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f68d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset_availability():\n",
    "    \"\"\"Check if datasets exist and display statistics\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Checking Dataset Availability\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    datasets_found = False\n",
    "    \n",
    "    if os.path.exists(DATASET_DIR):\n",
    "        print(f\"\\nâœ“ Processed dataset directory found: {DATASET_DIR}\")\n",
    "        \n",
    "        # Check open eyes\n",
    "        open_dir = os.path.join(DATASET_DIR, 'eye_open')\n",
    "        if os.path.exists(open_dir):\n",
    "            open_count = len([f for f in os.listdir(open_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "            print(f\"  âœ“ Open eye images: {open_count} files\")\n",
    "            if open_count > 0:\n",
    "                datasets_found = True\n",
    "        else:\n",
    "            print(f\"  âœ— Open eye directory not found\")\n",
    "        \n",
    "        # Check closed eyes\n",
    "        closed_dir = os.path.join(DATASET_DIR, 'eye_closed')\n",
    "        if os.path.exists(closed_dir):\n",
    "            closed_count = len([f for f in os.listdir(closed_dir) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "            print(f\"  âœ“ Closed eye images: {closed_count} files\")\n",
    "            if closed_count > 0:\n",
    "                datasets_found = True\n",
    "        else:\n",
    "            print(f\"  âœ— Closed eye directory not found\")\n",
    "    else:\n",
    "        print(f\"\\nâœ— Processed dataset directory not found: {DATASET_DIR}\")\n",
    "    \n",
    "    if not datasets_found:\n",
    "        print(\"\\n  WARNING: No processed datasets found!\")\n",
    "        print(\"\\n  Recommended: CEW Dataset or MRL Eye Dataset\")\n",
    "        print(\"   CEW: http://parnec.nuaa.edu.cn/xtan/data/ClosedEyeDatabases.html\")\n",
    "        print(\"   MRL: http://mrl.cs.vsb.cz/eyedataset\")\n",
    "        print(\"   OR use generate_sample_dataset() to create synthetic data for testing\")\n",
    "    else:\n",
    "        print(\"\\n Dataset is available and ready for training!\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    return datasets_found\n",
    "\n",
    "# Check datasets\n",
    "dataset_available = check_dataset_availability()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1399016a",
   "metadata": {},
   "source": [
    "## STAGE 5: Generate Sample Dataset (Optional)\n",
    "Run this cell only if you don't have real datasets. This creates synthetic eye images for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a739b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_dataset(num_samples=500):\n",
    "    \"\"\"Generate synthetic eye images for testing\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Generating Sample Dataset\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    os.makedirs(os.path.join(DATASET_DIR, 'eye_open'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(DATASET_DIR, 'eye_closed'), exist_ok=True)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Open eye (ellipse shape)\n",
    "        img_open = np.ones((IMG_SIZE, IMG_SIZE), dtype=np.uint8) * 200\n",
    "        cv2.ellipse(img_open, (IMG_SIZE//2, IMG_SIZE//2), (8, 5), 0, 0, 360, 50, -1)\n",
    "        cv2.circle(img_open, (IMG_SIZE//2, IMG_SIZE//2), 3, 0, -1)\n",
    "        noise = np.random.randint(-20, 20, (IMG_SIZE, IMG_SIZE), dtype=np.int16)\n",
    "        img_open = np.clip(img_open.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "        cv2.imwrite(os.path.join(DATASET_DIR, 'eye_open', f'open_{i:04d}.png'), img_open)\n",
    "        \n",
    "        # Closed eye (horizontal line)\n",
    "        img_closed = np.ones((IMG_SIZE, IMG_SIZE), dtype=np.uint8) * 200\n",
    "        cv2.line(img_closed, (4, IMG_SIZE//2), (IMG_SIZE-4, IMG_SIZE//2), 50, 2)\n",
    "        noise = np.random.randint(-20, 20, (IMG_SIZE, IMG_SIZE), dtype=np.int16)\n",
    "        img_closed = np.clip(img_closed.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "        cv2.imwrite(os.path.join(DATASET_DIR, 'eye_closed', f'closed_{i:04d}.png'), img_closed)\n",
    "    \n",
    "    print(f\"\\nâœ“ Generated {num_samples} open eye images\")\n",
    "    print(f\"âœ“ Generated {num_samples} closed eye images\")\n",
    "    print(f\"âœ“ Total: {num_samples * 2} synthetic images\")\n",
    "    print(\"\\n  Note: This is synthetic data for testing. Use real datasets for production.\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# Uncomment the line below to generate synthetic data if no real dataset is available\n",
    "# if not dataset_available:\n",
    "#     generate_sample_dataset(500)\n",
    "#     dataset_available = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4b0225",
   "metadata": {},
   "source": [
    "## STAGE 6: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b533d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_dir=DATASET_DIR):\n",
    "    \"\"\"Load preprocessed eye images\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Loading Dataset\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    # Load open eyes (label = 0)\n",
    "    open_dir = os.path.join(data_dir, 'eye_open')\n",
    "    if os.path.exists(open_dir):\n",
    "        open_files = [f for f in os.listdir(open_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        print(f\"\\nLoading {len(open_files)} open eye images...\")\n",
    "        for img_file in open_files:\n",
    "            img = cv2.imread(os.path.join(open_dir, img_file), cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                X.append(img)\n",
    "                y.append(0)\n",
    "    \n",
    "    # Load closed eyes (label = 1)\n",
    "    closed_dir = os.path.join(data_dir, 'eye_closed')\n",
    "    if os.path.exists(closed_dir):\n",
    "        closed_files = [f for f in os.listdir(closed_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "        print(f\"Loading {len(closed_files)} closed eye images...\")\n",
    "        for img_file in closed_files:\n",
    "            img = cv2.imread(os.path.join(closed_dir, img_file), cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                X.append(img)\n",
    "                y.append(1)\n",
    "    \n",
    "    # Convert to numpy arrays and normalize\n",
    "    X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1) / 255.0\n",
    "    y = np.array(y)\n",
    "    \n",
    "    print(f\"\\nâœ“ Loaded {len(X)} images total\")\n",
    "    print(f\"  - Open (0): {np.sum(y == 0)} images\")\n",
    "    print(f\"  - Closed (1): {np.sum(y == 1)} images\")\n",
    "    print(f\"\\nDataset shape: {X.shape}\")\n",
    "    print(f\"Value range: [{X.min():.3f}, {X.max():.3f}]\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    X, y = load_dataset()\n",
    "    if len(X) == 0:\n",
    "        print(\"\\n  No data found! Generate sample data or provide real dataset.\")\n",
    "    else:\n",
    "        print(\"\\n Dataset loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n   Error loading dataset: {e}\")\n",
    "    X, y = np.array([]), np.array([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d31567",
   "metadata": {},
   "source": [
    "## STAGE 7: Data Augmentation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db249f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_DATA_AUGMENTATION:\n",
    "    # Create ImageDataGenerator for augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    print(\" Data augmentation enabled:\")\n",
    "    print(\"   - Rotation: Â±10Â°\")\n",
    "    print(\"   - Width/Height shift: Â±10%\")\n",
    "    print(\"   - Zoom: Â±10%\")\n",
    "    print(\"   - Horizontal flip: Yes\")\n",
    "else:\n",
    "    datagen = None\n",
    "    print(\"  Data augmentation disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2337bc01",
   "metadata": {},
   "source": [
    "## STAGE 8: Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa80cf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X) > 0:\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 4))\n",
    "    fig.suptitle('Sample Eye Images', fontsize=16)\n",
    "    \n",
    "    # Get sample indices\n",
    "    open_indices = np.where(y == 0)[0][:5]\n",
    "    closed_indices = np.where(y == 1)[0][:5]\n",
    "    \n",
    "    # Plot open eye samples\n",
    "    for i, idx in enumerate(open_indices):\n",
    "        axes[0, i].imshow(X[idx].reshape(IMG_SIZE, IMG_SIZE), cmap='gray')\n",
    "        axes[0, i].set_title(f'Open #{i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "    \n",
    "    # Plot closed eye samples\n",
    "    for i, idx in enumerate(closed_indices):\n",
    "        axes[1, i].imshow(X[idx].reshape(IMG_SIZE, IMG_SIZE), cmap='gray')\n",
    "        axes[1, i].set_title(f'Closed #{i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Class distribution\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    ax.bar(['Open', 'Closed'], counts, color=['green', 'red'])\n",
    "    ax.set_ylabel('Number of Images')\n",
    "    ax.set_title('Class Distribution')\n",
    "    for i, count in enumerate(counts):\n",
    "        ax.text(i, count, str(count), ha='center', va='bottom')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0008fade",
   "metadata": {},
   "source": [
    "## STAGE 9: Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ed5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X) > 0:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SPLIT, random_state=RANDOM_SEED, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(\"\\n Dataset Split:\")\n",
    "    print(f\"  Training set: {len(X_train)} images\")\n",
    "    print(f\"    - Open: {np.sum(y_train == 0)}\")\n",
    "    print(f\"    - Closed: {np.sum(y_train == 1)}\")\n",
    "    print(f\"\\n  Test set: {len(X_test)} images\")\n",
    "    print(f\"    - Open: {np.sum(y_test == 0)}\")\n",
    "    print(f\"    - Closed: {np.sum(y_test == 1)}\")\n",
    "else:\n",
    "    print(\"  Cannot split dataset - no data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638525b2",
   "metadata": {},
   "source": [
    "## STAGE 10: Create Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309971c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"Create lightweight CNN for eye state detection\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(IMG_SIZE, IMG_SIZE, 1), name='input'),\n",
    "        \n",
    "        # Conv Block 1\n",
    "        layers.Conv2D(16, (3, 3), activation='relu', padding='same', name='conv1'),\n",
    "        layers.MaxPooling2D((2, 2), name='pool1'),\n",
    "        layers.Dropout(0.2, name='dropout1'),\n",
    "        \n",
    "        # Conv Block 2\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv2'),\n",
    "        layers.MaxPooling2D((2, 2), name='pool2'),\n",
    "        layers.Dropout(0.2, name='dropout2'),\n",
    "        \n",
    "        # Dense Layers\n",
    "        layers.Flatten(name='flatten'),\n",
    "        layers.Dense(16, activation='relu', name='dense1'),\n",
    "        layers.Dropout(0.3, name='dropout3'),\n",
    "        layers.Dense(1, activation='sigmoid', name='output')\n",
    "    ], name='eye_state_detector')\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and display model\n",
    "model = create_model()\n",
    "model.summary()\n",
    "\n",
    "# Calculate model size\n",
    "total_params = model.count_params()\n",
    "print(f\"\\n Model Size:\")\n",
    "print(f\"   Parameters: {total_params:,}\")\n",
    "print(f\"   FP32: {total_params * 4 / 1024:.2f} KB\")\n",
    "print(f\"   INT8: {total_params / 1024:.2f} KB\")\n",
    "print(f\"   Target: <20 KB {'âœ“' if total_params / 1024 < 20 else 'âœ—'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9393380",
   "metadata": {},
   "source": [
    "## STAGE 11: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a730797",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X) > 0:\n",
    "    print(\"\\n Starting training...\\n\")\n",
    "    \n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=0.00001,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            f'{MODEL_NAME}_best.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    if USE_DATA_AUGMENTATION and datagen is not None:\n",
    "        # Split training data for validation\n",
    "        X_train_fit, X_val, y_train_fit, y_val = train_test_split(\n",
    "            X_train, y_train, test_size=VALIDATION_SPLIT, random_state=RANDOM_SEED\n",
    "        )\n",
    "        \n",
    "        # Fit generator on training data\n",
    "        datagen.fit(X_train_fit)\n",
    "        \n",
    "        # Train with data augmentation\n",
    "        history = model.fit(\n",
    "            datagen.flow(X_train_fit, y_train_fit, batch_size=BATCH_SIZE),\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=EPOCHS,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "    else:\n",
    "        # Train without augmentation\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_split=VALIDATION_SPLIT,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "    \n",
    "    print(\"\\n Training completed!\")\n",
    "else:\n",
    "    print(\" Cannot train - no data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bb7b1d",
   "metadata": {},
   "source": [
    "## STAGE 12: Visualize Training History (4 Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e2e13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 0].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "    axes[0, 0].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].set_title('Model Accuracy')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 1].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "    axes[0, 1].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].set_title('Model Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Precision\n",
    "    axes[1, 0].plot(history.history['precision'], label='Train Precision', linewidth=2)\n",
    "    axes[1, 0].plot(history.history['val_precision'], label='Val Precision', linewidth=2)\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Precision')\n",
    "    axes[1, 0].set_title('Model Precision')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Recall\n",
    "    axes[1, 1].plot(history.history['recall'], label='Train Recall', linewidth=2)\n",
    "    axes[1, 1].plot(history.history['val_recall'], label='Val Recall', linewidth=2)\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Recall')\n",
    "    axes[1, 1].set_title('Model Recall')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675ecfec",
   "metadata": {},
   "source": [
    "## STAGE 13: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeadd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X) > 0:\n",
    "    print(\"\\nðŸ“Š Evaluating model on test set...\\n\")\n",
    "    \n",
    "    test_loss, test_acc, test_precision, test_recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "    f1_score = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
    "    \n",
    "    print(f\"Test Accuracy:  {test_acc * 100:.2f}%\")\n",
    "    print(f\"Test Loss:      {test_loss:.4f}\")\n",
    "    print(f\"Test Precision: {test_precision:.4f}\")\n",
    "    print(f\"Test Recall:    {test_recall:.4f}\")\n",
    "    print(f\"F1-Score:       {f1_score:.4f}\")\n",
    "    \n",
    "    if test_acc >= 0.95:\n",
    "        print(\"\\n Target accuracy (>95%) achieved!\")\n",
    "    else:\n",
    "        print(f\"\\n  Target not met. Current: {test_acc*100:.2f}%, Target: >95%\")\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_prob = model.predict(X_test, verbose=0)\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.set_xticklabels(['Open', 'Closed'])\n",
    "    ax.set_yticklabels(['Open', 'Closed'])\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification Report\n",
    "    print(\"\\nðŸ“‹ Classification Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Open', 'Closed']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddcbf08",
   "metadata": {},
   "source": [
    "## STAGE 14: Sample Predictions Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5875d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X) > 0:\n",
    "    # Select random samples\n",
    "    sample_indices = np.random.choice(len(X_test), 10, replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "    fig.suptitle('Sample Predictions', fontsize=16)\n",
    "    \n",
    "    for i, idx in enumerate(sample_indices):\n",
    "        row = i // 5\n",
    "        col = i % 5\n",
    "        \n",
    "        img = X_test[idx].reshape(IMG_SIZE, IMG_SIZE)\n",
    "        true_label = y_test[idx]\n",
    "        pred_prob = y_pred_prob[idx][0]\n",
    "        pred_label = 1 if pred_prob > 0.5 else 0\n",
    "        \n",
    "        axes[row, col].imshow(img, cmap='gray')\n",
    "        \n",
    "        color = 'green' if pred_label == true_label else 'red'\n",
    "        title = f\"True: {'Closed' if true_label == 1 else 'Open'}\\n\"\n",
    "        title += f\"Pred: {'Closed' if pred_label == 1 else 'Open'} ({pred_prob:.2f})\"\n",
    "        axes[row, col].set_title(title, color=color, fontsize=9)\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85793bc4",
   "metadata": {},
   "source": [
    "## STAGE 15: Convert to TensorFlow Lite for ESP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d093cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tflite(model, model_name):\n",
    "    \"\"\"Convert Keras model to TensorFlow Lite\"\"\"\n",
    "    print(\"\\nðŸ”„ Converting to TensorFlow Lite...\\n\")\n",
    "    \n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    # Save TFLite\n",
    "    tflite_filename = f'{model_name}.tflite'\n",
    "    with open(tflite_filename, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    \n",
    "    print(f\"âœ“ Saved: {tflite_filename}\")\n",
    "    print(f\"âœ“ Model size: {len(tflite_model) / 1024:.2f} KB\")\n",
    "    \n",
    "    if len(tflite_model) / 1024 < 20:\n",
    "        print(\" Size target met (<20KB)!\")\n",
    "    \n",
    "    # Save as C header for ESP32\n",
    "    h_filename = f'{model_name}.h'\n",
    "    with open(h_filename, 'w') as f:\n",
    "        f.write(f\"// Auto-generated for ESP32\\n\")\n",
    "        f.write(f\"// Model: {model_name}\\n\")\n",
    "        f.write(f\"// Size: {len(tflite_model)} bytes\\n\\n\")\n",
    "        f.write(f\"#ifndef {model_name.upper()}_H\\n\")\n",
    "        f.write(f\"#define {model_name.upper()}_H\\n\\n\")\n",
    "        f.write(f\"const unsigned char {model_name}_tflite[] = {{\\n\")\n",
    "        \n",
    "        hex_array = [f\"0x{byte:02x}\" for byte in tflite_model]\n",
    "        for i in range(0, len(hex_array), 12):\n",
    "            f.write(\"  \" + \", \".join(hex_array[i:i+12]) + \",\\n\")\n",
    "        \n",
    "        f.write(\"};\\n\\n\")\n",
    "        f.write(f\"const unsigned int {model_name}_tflite_len = {len(tflite_model)};\\n\\n\")\n",
    "        f.write(f\"#endif\\n\")\n",
    "    \n",
    "    print(f\"âœ“ Saved: {h_filename}\")\n",
    "    print(\"\\n Conversion completed!\")\n",
    "    \n",
    "    return tflite_model\n",
    "\n",
    "# Convert model\n",
    "if len(X) > 0:\n",
    "    tflite_model = convert_to_tflite(model, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96f4967",
   "metadata": {},
   "source": [
    "## STAGE 16: Save Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2904056",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X) > 0:\n",
    "    keras_filename = f'{MODEL_NAME}.h5'\n",
    "    model.save(keras_filename)\n",
    "    print(f\"âœ“ Saved Keras model: {keras_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cc056e",
   "metadata": {},
   "source": [
    "## STAGE 17: Test Inference Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ea5388",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X) > 0:\n",
    "    import time\n",
    "    \n",
    "    print(\"\\n  Testing inference speed...\\n\")\n",
    "    \n",
    "    test_image = X_test[0:1]\n",
    "    \n",
    "    # Warm up\n",
    "    for _ in range(10):\n",
    "        _ = model.predict(test_image, verbose=0)\n",
    "    \n",
    "    # Measure\n",
    "    num_iterations = 100\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_iterations):\n",
    "        _ = model.predict(test_image, verbose=0)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    avg_time = (end_time - start_time) / num_iterations * 1000\n",
    "    fps = 1000 / avg_time\n",
    "    \n",
    "    print(f\"Average inference time: {avg_time:.2f} ms\")\n",
    "    print(f\"Estimated FPS: {fps:.2f}\")\n",
    "    print(f\"\\nNote: ESP32 will be slower (~50-100ms per inference)\")\n",
    "    print(f\"Target FPS on ESP32: ~10-20 FPS\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
